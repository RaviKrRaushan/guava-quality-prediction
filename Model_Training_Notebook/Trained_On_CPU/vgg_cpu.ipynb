{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaBkWakxFX_Q"
      },
      "source": [
        "# All imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC5ySlmu6QnV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Concatenate, Input, Add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ_vsIwWFd4f"
      },
      "source": [
        "# Drive Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0-XPmnA8HaS",
        "outputId": "fd06b418-8ceb-4680-d80e-5ea8aa72babf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCwdmtp58HXu"
      },
      "outputs": [],
      "source": [
        "input_dirs = {\n",
        "    'rotten': '/content/drive/MyDrive/data/rotten',\n",
        "    'mid': '/content/drive/MyDrive/data/mid',\n",
        "    'fresh': '/content/drive/MyDrive/data/fresh'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDncosME8HU9"
      },
      "outputs": [],
      "source": [
        "output_dirs = {\n",
        "    'rotten': '/content/drive/MyDrive/data/rotten_frames',\n",
        "    'mid': '/content/drive/MyDrive/data/mid_frames',\n",
        "    'fresh': '/content/drive/MyDrive/data/fresh_frames'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmW9E_288HSP"
      },
      "outputs": [],
      "source": [
        "for category, out_dir in output_dirs.items():\n",
        "    os.makedirs(out_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs59wdk_FqUS"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn4aLjhNFj0q"
      },
      "source": [
        "## Frame Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4KxrbGo8HJ9",
        "outputId": "d98b873a-5e01-402d-e26c-c92d4d79fe4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in fresh_frames: 110\n",
            "Number of images in mid_frames: 130\n",
            "Number of images in rotten_frames: 60\n"
          ]
        }
      ],
      "source": [
        "fresh_frames_dir = '/content/drive/MyDrive/data/fresh_frames'\n",
        "mid_frames_dir = '/content/drive/MyDrive/data/mid_frames'\n",
        "rotten_frames_dir = '/content/drive/MyDrive/data/rotten_frames'\n",
        "\n",
        "fresh_images_count = len([file for file in os.listdir(fresh_frames_dir) if file.endswith('.jpg')])\n",
        "mid_images_count = len([file for file in os.listdir(mid_frames_dir) if file.endswith('.jpg')])\n",
        "rotten_images_count = len([file for file in os.listdir(rotten_frames_dir) if file.endswith('.jpg')])\n",
        "\n",
        "print(f\"Number of images in fresh_frames: {fresh_images_count}\")\n",
        "print(f\"Number of images in mid_frames: {mid_images_count}\")\n",
        "print(f\"Number of images in rotten_frames: {rotten_images_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXr2IEdF3Lv"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3uYc8wlNlbu",
        "outputId": "12fc0a14-ef88-4312-f79a-a45761909347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in augmented_fresh_frames: 1100\n",
            "Number of images in augmented_mid_frames: 1300\n",
            "Number of images in augmented_rotten_frames: 600\n"
          ]
        }
      ],
      "source": [
        "base_path = \"/content/drive/MyDrive/data/augmented\"\n",
        "\n",
        "folders = {\n",
        "    \"fresh\": \"augmented_fresh_frames\",\n",
        "    \"mid\": \"augmented_mid_frames\",\n",
        "    \"rotten\": \"augmented_rotten_frames\"\n",
        "}\n",
        "\n",
        "for label, folder in folders.items():\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "    print(f\"Number of images in {folder}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIt92fEL8HHc"
      },
      "outputs": [],
      "source": [
        "rotten_dir = os.path.join(base_path, 'augmented_rotten_frames')\n",
        "mid_dir = os.path.join(base_path, 'augmented_mid_frames')\n",
        "fresh_dir = os.path.join(base_path, 'augmented_fresh_frames')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W56kI1My3XEQ",
        "outputId": "c969bee1-2ca5-4dc8-8e8e-4d7b4445208a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: {0: 5, 1: 2, 2: 2}\n"
          ]
        }
      ],
      "source": [
        "# Class weights (handle imbalance)\n",
        "total_images = {\n",
        "    'rotten': 600,\n",
        "    'mid': 1300,\n",
        "    'fresh': 1100\n",
        "}\n",
        "\n",
        "total = sum(total_images.values())\n",
        "\n",
        "# 0 - rotten, 1 - mid, 2 - fresh\n",
        "class_weights = {\n",
        "    0: int(total / total_images['rotten']),  # rotten\n",
        "    1: int(total / total_images['mid']),     # mid\n",
        "    2: int(total / total_images['fresh'])    # fresh\n",
        "}\n",
        "\n",
        "print(\"Class Weights:\", class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntEHNi7ywAeq",
        "outputId": "e7d5d259-c3e9-47e9-94ab-c106312db8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2100 images belonging to 3 classes.\n",
            "Found 900 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    validation_split=0.3,\n",
        ")\n",
        "#Training data\n",
        "train_data = datagen.flow_from_directory(\n",
        "    base_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "#Validation data\n",
        "val_data = datagen.flow_from_directory(\n",
        "    base_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiwOHCiZFQgf"
      },
      "source": [
        "# Models Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2S9ay2PAdYV"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMG9jb1MiZJE",
        "outputId": "3c3582f8-f4f4-42dd-befa-41493b3cf275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2100 images belonging to 3 classes.\n",
            "Found 900 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "#RGB to BGR\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "datagen_vgg = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "#Loading training data\n",
        "train_data_vgg = datagen_vgg.flow_from_directory(\n",
        "    base_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "#Loading validation data\n",
        "val_data_vgg = datagen_vgg.flow_from_directory(\n",
        "    base_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5FB5p1CizPc",
        "outputId": "1dbb8cd8-f164-4bb3-dc39-6073428edbe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "#Loading vgg16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freezing the base layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Model Building\n",
        "model_vgg = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "4l9dgn8qizL1",
        "outputId": "d33b7f74-9b7a-4938-f473-4285f8955104"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m771\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,846,787</span> (56.64 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,846,787\u001b[0m (56.64 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132,099</span> (516.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132,099\u001b[0m (516.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Compilation\n",
        "model_vgg.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Model summary\n",
        "model_vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67wfhuE6izJN",
        "outputId": "bd849b84-5684-458d-f07e-c9f6a779b064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.4607 - loss: 3.3713 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.87667, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2040s\u001b[0m 31s/step - accuracy: 0.4624 - loss: 3.3545 - val_accuracy: 0.8767 - val_loss: 0.4108 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.7752 - loss: 1.0767 \n",
            "Epoch 2: val_accuracy improved from 0.87667 to 0.90444, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1973s\u001b[0m 30s/step - accuracy: 0.7754 - loss: 1.0747 - val_accuracy: 0.9044 - val_loss: 0.3522 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.8245 - loss: 0.7235 \n",
            "Epoch 3: val_accuracy improved from 0.90444 to 0.91889, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1897s\u001b[0m 29s/step - accuracy: 0.8247 - loss: 0.7234 - val_accuracy: 0.9189 - val_loss: 0.2602 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.8623 - loss: 0.5721 \n",
            "Epoch 4: val_accuracy improved from 0.91889 to 0.92667, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1901s\u001b[0m 29s/step - accuracy: 0.8623 - loss: 0.5716 - val_accuracy: 0.9267 - val_loss: 0.1936 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.8695 - loss: 0.5074 \n",
            "Epoch 5: val_accuracy improved from 0.92667 to 0.92778, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1910s\u001b[0m 29s/step - accuracy: 0.8696 - loss: 0.5065 - val_accuracy: 0.9278 - val_loss: 0.2047 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.8757 - loss: 0.4133 \n",
            "Epoch 6: val_accuracy improved from 0.92778 to 0.93667, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1899s\u001b[0m 29s/step - accuracy: 0.8759 - loss: 0.4125 - val_accuracy: 0.9367 - val_loss: 0.1587 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9115 - loss: 0.2946 \n",
            "Epoch 7: val_accuracy improved from 0.93667 to 0.94333, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1901s\u001b[0m 29s/step - accuracy: 0.9114 - loss: 0.2949 - val_accuracy: 0.9433 - val_loss: 0.1578 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9003 - loss: 0.3329 \n",
            "Epoch 8: val_accuracy improved from 0.94333 to 0.94556, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1904s\u001b[0m 29s/step - accuracy: 0.9004 - loss: 0.3322 - val_accuracy: 0.9456 - val_loss: 0.1352 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9227 - loss: 0.2047 \n",
            "Epoch 9: val_accuracy did not improve from 0.94556\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1943s\u001b[0m 30s/step - accuracy: 0.9225 - loss: 0.2054 - val_accuracy: 0.9456 - val_loss: 0.1406 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9083 - loss: 0.2529 \n",
            "Epoch 10: val_accuracy did not improve from 0.94556\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1908s\u001b[0m 29s/step - accuracy: 0.9084 - loss: 0.2528 - val_accuracy: 0.9378 - val_loss: 0.1227 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9375 - loss: 0.1826 \n",
            "Epoch 11: val_accuracy did not improve from 0.94556\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1966s\u001b[0m 30s/step - accuracy: 0.9374 - loss: 0.1828 - val_accuracy: 0.9411 - val_loss: 0.1182 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9252 - loss: 0.2058 \n",
            "Epoch 12: val_accuracy improved from 0.94556 to 0.94667, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1926s\u001b[0m 29s/step - accuracy: 0.9253 - loss: 0.2059 - val_accuracy: 0.9467 - val_loss: 0.1196 - learning_rate: 2.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9292 - loss: 0.2234 \n",
            "Epoch 13: val_accuracy improved from 0.94667 to 0.94778, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1948s\u001b[0m 30s/step - accuracy: 0.9293 - loss: 0.2232 - val_accuracy: 0.9478 - val_loss: 0.1159 - learning_rate: 2.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9270 - loss: 0.2234 \n",
            "Epoch 14: val_accuracy improved from 0.94778 to 0.94889, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1908s\u001b[0m 29s/step - accuracy: 0.9270 - loss: 0.2232 - val_accuracy: 0.9489 - val_loss: 0.1145 - learning_rate: 2.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.9298 - loss: 0.2131 \n",
            "Epoch 15: val_accuracy improved from 0.94889 to 0.95111, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1936s\u001b[0m 29s/step - accuracy: 0.9298 - loss: 0.2129 - val_accuracy: 0.9511 - val_loss: 0.1139 - learning_rate: 2.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21s/step - accuracy: 0.9390 - loss: 0.1583 \n",
            "Epoch 16: val_accuracy did not improve from 0.95111\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1936s\u001b[0m 29s/step - accuracy: 0.9390 - loss: 0.1586 - val_accuracy: 0.9478 - val_loss: 0.1125 - learning_rate: 2.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9228 - loss: 0.1848 \n",
            "Epoch 17: val_accuracy did not improve from 0.95111\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1920s\u001b[0m 29s/step - accuracy: 0.9229 - loss: 0.1849 - val_accuracy: 0.9500 - val_loss: 0.1151 - learning_rate: 2.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9442 - loss: 0.1502 \n",
            "Epoch 18: val_accuracy did not improve from 0.95111\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1960s\u001b[0m 30s/step - accuracy: 0.9440 - loss: 0.1508 - val_accuracy: 0.9500 - val_loss: 0.1136 - learning_rate: 2.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9346 - loss: 0.1588 \n",
            "Epoch 19: val_accuracy did not improve from 0.95111\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1919s\u001b[0m 29s/step - accuracy: 0.9346 - loss: 0.1590 - val_accuracy: 0.9511 - val_loss: 0.1134 - learning_rate: 4.0000e-06\n",
            "Epoch 20/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9328 - loss: 0.1947 \n",
            "Epoch 20: val_accuracy did not improve from 0.95111\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1923s\u001b[0m 29s/step - accuracy: 0.9328 - loss: 0.1947 - val_accuracy: 0.9500 - val_loss: 0.1129 - learning_rate: 4.0000e-06\n",
            "Epoch 21/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9321 - loss: 0.1998 \n",
            "Epoch 21: val_accuracy improved from 0.95111 to 0.95333, saving model to vgg_cpu.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1904s\u001b[0m 29s/step - accuracy: 0.9322 - loss: 0.1996 - val_accuracy: 0.9533 - val_loss: 0.1130 - learning_rate: 4.0000e-06\n",
            "Epoch 22/50\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20s/step - accuracy: 0.9356 - loss: 0.1772 \n",
            "Epoch 22: val_accuracy did not improve from 0.95333\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1963s\u001b[0m 30s/step - accuracy: 0.9357 - loss: 0.1771 - val_accuracy: 0.9533 - val_loss: 0.1126 - learning_rate: 4.0000e-06\n",
            "Epoch 23/50\n",
            "\u001b[1m 4/66\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:52\u001b[0m 20s/step - accuracy: 0.9284 - loss: 0.2011"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import time\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_vgg = ModelCheckpoint(\n",
        "    \"vgg_cpu.h5\",\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr_vgg = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping_vgg = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Start training\n",
        "start_vgg = time.time()\n",
        "\n",
        "history_vgg = model_vgg.fit(\n",
        "    train_data_vgg,\n",
        "    epochs=50,\n",
        "    validation_data=val_data_vgg,\n",
        "    callbacks=[checkpoint_vgg, reduce_lr_vgg, early_stopping_vgg]\n",
        ")\n",
        "\n",
        "end_vgg = time.time()\n",
        "runtime_vgg = end_vgg - start_vgg\n",
        "\n",
        "print(f\"Training Time for VGG16 model: {runtime_vgg:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwLObAwnizGV",
        "outputId": "e0ee435d-8566-46ad-e41f-103445930840"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# model_vgg = load_model(\"vgg_cpu.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FU5Nq1Z2v083",
        "FGbTcpMK6O39",
        "5ZJbr5tmjXTd",
        "ZnyDsBROrS6v",
        "uH4nkXwQy6sJ",
        "_ewYyuf2Di2R",
        "kg7WAYmiEw_1",
        "Blt85sRZXCjW"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
